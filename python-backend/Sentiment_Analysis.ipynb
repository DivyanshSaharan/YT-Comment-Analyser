{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gXiqDegRgx5"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, GRU, Bidirectional, Input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUD7hz12SAAa",
        "outputId": "e6c3d303-9f68-4b63-df06-33237b09f4b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rOvSL6EbRrez"
      },
      "outputs": [],
      "source": [
        "# Importing Dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dataset/test.csv\")\n",
        "# df = pd.read_csv(\"/content/comments.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQd2iCGdRwBK",
        "outputId": "5876f80f-b9ad-4cbd-fa72-d5cb2d5f1abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3534, 2)\n",
            "Index(['text', 'sentiment'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Data Info\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "esXGYD3SSDX3"
      },
      "outputs": [],
      "source": [
        "sentiment_mapping = {\n",
        "    'positive': 1,\n",
        "    'negative': 0,\n",
        "    'neutral': 2\n",
        "}\n",
        "\n",
        "# Encode sentiments\n",
        "df['sentiment'] = df['sentiment'].map(sentiment_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bws7ULgkSc7b"
      },
      "outputs": [],
      "source": [
        "x = df[\"text\"]\n",
        "y = df[\"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "SgVqtaDLS781",
        "outputId": "cb7208d9-6037-4a9c-b08a-3fd6303d8b9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Last session of the day  http://twitpic.com/67ezh\n",
              "1     Shanghai is also really exciting (precisely -...\n",
              "2    Recession hit Veronique Branquinho, she has to...\n",
              "3                                          happy bday!\n",
              "4               http://twitpic.com/4w75p - I like it!!\n",
              "Name: text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>happy bday!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_DiVBMvqSjAI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def remove_links(text):\n",
        "    # Regular expression to find URLs\n",
        "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    return re.sub(url_pattern, '', text)\n",
        "\n",
        "x = x.apply(remove_links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Hm_Pu7noTIeL",
        "outputId": "8e7db85b-1f52-4b11-e54f-3eac7a7cde50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                              Last session of the day\n",
              "1    Shanghai is also really exciting precisely  sk...\n",
              "2    Recession hit Veronique Branquinho she has to ...\n",
              "3                                           happy bday\n",
              "4                                            I like it\n",
              "Name: text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Last session of the day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shanghai is also really exciting precisely  sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recession hit Veronique Branquinho she has to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>happy bday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I like it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hfs15ghzXGtU"
      },
      "outputs": [],
      "source": [
        "def remove_non_alpha(text):\n",
        "    # Use regular expression to replace non-alphabetical characters with a space\n",
        "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "def strip_whitespaces(text):\n",
        "    return text.strip()  # Remove leading and trailing whitespaces\n",
        "\n",
        "x = x.apply(remove_non_alpha)\n",
        "x = x.apply(strip_whitespaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "SvC1wi5vXNnw",
        "outputId": "c7ab45b5-c948-4084-9b5e-81329f79b65d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                              Last session of the day\n",
              "1    Shanghai is also really exciting precisely  sk...\n",
              "2    Recession hit Veronique Branquinho she has to ...\n",
              "3                                           happy bday\n",
              "4                                            I like it\n",
              "Name: text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Last session of the day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shanghai is also really exciting precisely  sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recession hit Veronique Branquinho she has to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>happy bday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I like it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QZyD7ampn-Ew"
      },
      "outputs": [],
      "source": [
        "# # Adding additional data\n",
        "# df1 = pd.read_csv(\"/content/extra_data.csv\")\n",
        "# df1['sentiment'] = df1['sentiment'].map(sentiment_mapping)\n",
        "# x_new = df1['text']\n",
        "# y_new = df1['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Cob3KQYxncnV"
      },
      "outputs": [],
      "source": [
        "# x = pd.concat([x,x_new])\n",
        "# y = pd.concat([y,y_new])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SP_m75Loxjb",
        "outputId": "372da80e-e69c-46ea-d06a-24f9da302478"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3534,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "B0EbJF5dXRL2"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(x)\n",
        "sequences = tokenizer.texts_to_sequences(x)\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max(len(X) for X in sequences)\n",
        "padded_sequences = pad_sequences(sequences, padding='post', maxlen=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XDBW0NUSX_2k"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E_EwW1fN9fzD"
      },
      "outputs": [],
      "source": [
        "# defining Attention Layer\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1]),\n",
        "                                 initializer='glorot_uniform',\n",
        "                                 trainable=True)\n",
        "        self.b = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer='zeros',\n",
        "                                 trainable=True)\n",
        "        self.u = self.add_weight(shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform',\n",
        "                                 trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Score computation\n",
        "        u_it = K.tanh(K.dot(inputs, self.W) + self.b)\n",
        "        ait = K.softmax(K.dot(u_it, self.u), axis=1)\n",
        "        # Weighted sum of input vectors\n",
        "        output = inputs * ait\n",
        "        return K.sum(output, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training new embeddings"
      ],
      "metadata": {
        "id": "A6J0aDF9PQrM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Xw19YMs89k4X"
      },
      "outputs": [],
      "source": [
        "max_words = max_length  # Max words in each sentence\n",
        "vocab_size = 10000      # Vocabulary size\n",
        "embedding_dim = 50      # Embedding dimension\n",
        "\n",
        "# Input layer for sentences\n",
        "input_sentence = Input(shape=(max_words,))\n",
        "embedded_sentence = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_sentence)\n",
        "\n",
        "# Bi-directional GRU for word encoding\n",
        "sentence_encoded = Bidirectional(GRU(50, return_sequences=True))(embedded_sentence)\n",
        "\n",
        "# Word-level attention\n",
        "sentence_attended = AttentionLayer()(sentence_encoded)\n",
        "\n",
        "# Output layer for sentiment classification\n",
        "output = Dense(3, activation='softmax')(sentence_attended)  # Three classes: positive, negative, neutral\n",
        "\n",
        "# Define and compile the model\n",
        "model = Model(input_sentence, output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSUDPr5RYzXv",
        "outputId": "5e708ab4-47c3-4dd2-eb49-202d219f8e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 33ms/step - accuracy: 0.4452 - loss: 1.0390 - val_accuracy: 0.6238 - val_loss: 0.8243\n",
            "Epoch 2/6\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7617 - loss: 0.5826 - val_accuracy: 0.6436 - val_loss: 0.8553\n",
            "Epoch 3/6\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.8967 - loss: 0.3041 - val_accuracy: 0.6393 - val_loss: 1.1151\n",
            "Epoch 4/6\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.9516 - loss: 0.1373 - val_accuracy: 0.6082 - val_loss: 1.2938\n",
            "Epoch 5/6\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.9835 - loss: 0.0626 - val_accuracy: 0.6124 - val_loss: 1.5164\n",
            "Epoch 6/6\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.9946 - loss: 0.0267 - val_accuracy: 0.5941 - val_loss: 1.9913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e76dafc1510>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=6, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Al-p_4h_Q7l",
        "outputId": "7f9f7403-f5a0-4c75-b6fd-cfa22cb4d052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
            "The sentiment of the sentence 'this video is bad' is: negative\n"
          ]
        }
      ],
      "source": [
        "# For Making Predictions on New Data\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = remove_links(sentence)\n",
        "    sentence = remove_non_alpha(sentence)\n",
        "    sentence = strip_whitespaces(sentence)\n",
        "    sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_words, padding='post', truncating='post')\n",
        "    return padded_sequence\n",
        "\n",
        "def predict_sentiment(sentence, label_mapping):\n",
        "    # Preprocess the sentence\n",
        "    processed_sentence = preprocess_sentence(sentence)\n",
        "    # Get the model's prediction\n",
        "    prediction = model.predict(processed_sentence)\n",
        "    # Get the index of the max prediction score\n",
        "    predicted_class = np.argmax(prediction, axis=-1)[0]\n",
        "    # Map the index back to the label\n",
        "    sentiment = {v: k for k, v in label_mapping.items()}[predicted_class]\n",
        "    return sentiment\n",
        "\n",
        "# Example Usage\n",
        "sentence = \"this video is bad\"\n",
        "label_mapping = {\"positive\": 1, \"negative\": 0, \"neutral\": 2}  # Same as training\n",
        "sentiment = predict_sentiment(sentence, label_mapping)\n",
        "\n",
        "print(f\"The sentiment of the sentence '{sentence}' is: {sentiment}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Model"
      ],
      "metadata": {
        "id": "pYUNl3OsOkFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Model\n",
        "\n",
        "# model = Sequential([\n",
        "#     Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "#     LSTM(64, return_sequences=False),\n",
        "#     Dense(32, activation='relu'),\n",
        "#     Dense(3, activation='softmax')  # Output layer for three classes: positive, negative, neutral\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6980AvlyOA-a"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zX5Gg_fmcLEd"
      },
      "outputs": [],
      "source": [
        "# embeddings = model.layers[0](X)  # => Obtaining Embeddings\n",
        "# features = tf.keras.backend.eval(embeddings)\n",
        "# X_flat = np.mean(features, axis=1)  => Global Average Pooling\n",
        "# # X_flat = features.reshape(X.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5lPwLrCgcVRL"
      },
      "outputs": [],
      "source": [
        "# Applying Random Forest for Robustness and Prevent Overfitting\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)\n",
        "# rf_model = RandomForestClassifier()\n",
        "# rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FWDEaYENdUgs"
      },
      "outputs": [],
      "source": [
        "# def predict_sentiment(new_sentence):\n",
        "#     new_sentence = remove_non_alpha(new_sentence)\n",
        "#     new_sentence = strip_whitespaces(new_sentence)\n",
        "\n",
        "#     sequence = tokenizer.texts_to_sequences([new_sentence])\n",
        "#     # Pad the sequence\n",
        "#     padded_sequence = pad_sequences(sequence, padding='post', maxlen=max_length)\n",
        "\n",
        "#     # Getting embeddings from the RNN model\n",
        "#     embeddings = model.layers[0](padded_sequence)\n",
        "#     embeddings_np = tf.keras.backend.eval(embeddings)  # Convert to numpy array\n",
        "#     embeddings_np1 = np.mean(embeddings_np, axis=1)\n",
        "\n",
        "#     # Using the Random Forest model for prediction\n",
        "#     prediction = rf_model.predict(embeddings_np1)\n",
        "\n",
        "#     return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "c24PJEawegfu"
      },
      "outputs": [],
      "source": [
        "# new_sentence = \"It is not bad\"\n",
        "# predicted_label = predict_sentiment(new_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing Models Params and Tokenizer"
      ],
      "metadata": {
        "id": "Fms9QfnoPjye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'model_1.joblib')\n",
        "# model.save('model_1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxmFGOkf3Pt",
        "outputId": "c58c0a60-5894-42ef-f1dd-afd05f535bfd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_1.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('tokenizer.pkl', 'wb') as file:\n",
        "    pickle.dump(tokenizer, file)"
      ],
      "metadata": {
        "id": "VKxkN2kYgWLz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pQ7AzQEoTnZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}